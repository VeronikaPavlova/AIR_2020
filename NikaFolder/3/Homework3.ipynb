{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../build')\n",
    "import cv2 as cv\n",
    "import libry as ry\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from skimage.measure import compare_ssim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#-- Add REAL WORLD configuration and camera\n",
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../../scenarios/challenge.g\")\n",
    "S = RealWorld.simulation(ry.SimulatorEngine.physx, True)\n",
    "\n",
    "#RealWorld.getFrameNames()\n",
    "\n",
    "#Change color of objects\n",
    "RealWorld.frame(\"obj1\").setColor([1.,.0,.0])\n",
    "RealWorld.frame(\"obj13\").setColor([1.,.0,.0])\n",
    "RealWorld.frame(\"obj2\").setColor([1.,.0,.0])\n",
    "RealWorld.frame(\"obj23\").setColor([1.,.0,.0])\n",
    "RealWorld.frame(\"obj19\").setColor([1.,.0,.0])\n",
    "S.addSensor(\"camera\")\n",
    "\n",
    "\n",
    "C = ry.Config()\n",
    "C.addFile('../../scenarios/pandasTable.g')\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(C)\n",
    "cameraFrame = C.frame(\"camera\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#the focal length\n",
    "#f = 0.895\n",
    "f = 0.7\n",
    "f = f * 360.\n",
    "#the relative pose of the camera\n",
    "# pcl.setRelativePose('d(-90 0 0 1) t(-.08 .205 .115) d(26 1 0 0) d(-1 0 1 0) d(6 0 0 1) ')\n",
    "fxfypxpy = [f, f, 320., 180.]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Exercise 1\n",
    "1.) Filter the color of the image to find all pixels that are redish.\n",
    "2.) Display the binary image that indicates red pixels.\n",
    "3.) Fit contours to this binary image, which returns the segments.\n",
    "4.) Display the contours by drawing them into the original RGB image\n",
    "\n",
    "convexHull? Check out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "points = []\n",
    "tau = .01\n",
    "\n",
    "for t in range(300):\n",
    "    time.sleep(0.03)\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "\n",
    "        [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "        points = S.depthData2pointCloud(depth, fxfypxpy)\n",
    "        cameraFrame.setPointCloud(points, rgb)\n",
    "        V.recopyMeshes(C)\n",
    "        V.setConfiguration(C)\n",
    "\n",
    "        #use hsv - simpler for color finding\n",
    "        hsv = cv.cvtColor(rgb, cv.COLOR_BGR2HSV)\n",
    "\n",
    "        lower_red = np.array([115, 100, 100])\n",
    "        upper_red = np.array([130, 255, 255])\n",
    "\n",
    "        mask = cv.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "        #find contours adn draw in rgb image\n",
    "        contours, hierarchy = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        cv.drawContours(rgb, contours, -1, (0, 255, 0), 3)\n",
    "\n",
    "        if len(rgb)>0: cv.imshow('OPENCV - rgb', rgb)\n",
    "        #if len(hsv)>0: cv.imshow('OPENCV - hsv', hsv)\n",
    "        if len(mask)>0: cv.imshow('OPENCV - mask', mask)\n",
    "\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    S.step([], tau, ry.ControlMode.none)\n",
    "\n",
    "\n",
    "\n",
    "#hsv = cv.cvtColor(cameraFrame, cv.COLOR_BGR2HSV)\n",
    "#cv.imshow('HSV', hsv)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 2\n",
    "1.) Store the first image as background image. (Or average over several first images.)\n",
    "2.) For every new image filter those pixels, that are significantly different to the background.\n",
    "3.) Display the binary image that indicates change pixels.\n",
    "4.) Fit contours to this binary image, which returns the segments.\n",
    "5.) Display the contours by drawing them into the original RGB image\n",
    "6.) Test the same pipeline, but first smoothing/blurring the image\n",
    "\n",
    "\n",
    "Extra - compare_ssim\n",
    "\n",
    "The score\n",
    "  represents the structural similarity index between the two input images. This value can fall into the range [-1, 1] with a value of one being a “perfect match”.\n",
    "\n",
    "The diff\n",
    "  image contains the actual image differences between the two input images that we wish to visualize. The difference image is currently represented as a floating point data type in the range [0, 1] so we first convert the array to 8-bit unsigned integers in the range [0, 255] (Line 26) before we can further process it using OpenCV."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nika/.local/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM: 1.0\n",
      "SSIM: 0.9145864963243804\n",
      "SSIM: 0.8708617628128281\n",
      "SSIM: 0.8354997643390504\n",
      "SSIM: 0.7867769965631851\n",
      "SSIM: 0.7680874534436792\n",
      "SSIM: 0.7736531145853235\n",
      "SSIM: 0.8268022636690561\n",
      "SSIM: 0.8254909459814985\n",
      "SSIM: 0.8201170242046291\n",
      "SSIM: 0.8305374215688\n",
      "SSIM: 0.8603625542976248\n",
      "SSIM: 0.8591972029020896\n",
      "SSIM: 0.8833335264891294\n",
      "SSIM: 0.9227681185622427\n",
      "SSIM: 0.9623136416475\n",
      "SSIM: 0.9497003168470564\n",
      "SSIM: 0.94917242134912\n",
      "SSIM: 0.9727469186395067\n",
      "SSIM: 0.959109122856326\n",
      "SSIM: 0.9643392837185566\n",
      "SSIM: 0.9774839873200998\n",
      "SSIM: 0.9920056877216228\n",
      "SSIM: 0.979274061500213\n",
      "SSIM: 0.974684764212507\n",
      "SSIM: 0.9796662986135392\n",
      "SSIM: 0.9836855495229825\n",
      "SSIM: 0.9736877091517989\n",
      "SSIM: 0.9763850126964138\n",
      "SSIM: 0.9802497749127673\n",
      "SSIM: 0.9884421034146312\n",
      "SSIM: 0.9942123283809479\n",
      "SSIM: 0.986388566429694\n",
      "SSIM: 0.9799009466321782\n",
      "SSIM: 0.9779691158716421\n",
      "SSIM: 0.9899201217976052\n",
      "SSIM: 0.9834553509680252\n",
      "SSIM: 0.9794029965539252\n",
      "SSIM: 0.98624773311601\n",
      "SSIM: 0.992737418222676\n",
      "SSIM: 0.981649154155768\n",
      "SSIM: 0.9837772208240958\n",
      "SSIM: 0.9911030480583221\n",
      "SSIM: 0.9854482380301979\n",
      "SSIM: 0.9951277420579808\n",
      "SSIM: 0.9900037136778419\n",
      "SSIM: 0.9900690435998448\n",
      "SSIM: 0.9867057920805412\n",
      "SSIM: 0.9979531858705318\n",
      "SSIM: 0.987981717400593\n"
     ]
    }
   ],
   "source": [
    "[ref_rgb, ref_depth] = S.getImageAndDepth()\n",
    "\n",
    "points = []\n",
    "tau = .01\n",
    "\n",
    "for t in range(500):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "        [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "        points = S.depthData2pointCloud(depth, fxfypxpy)\n",
    "        cameraFrame.setPointCloud(points, rgb)\n",
    "        V.recopyMeshes(C)\n",
    "        V.setConfiguration(C)\n",
    "\n",
    "        #not sure why?\n",
    "        #ref_rgb = cv.blur(ref_rgb,(5,5))\n",
    "        #ref_rgb = cv.GaussianBlur(ref_rgb,(5,5),0)\n",
    "        #rgb = cv.GaussianBlur(rgb,(5,5),0)\n",
    "\n",
    "\n",
    "        # Convert images to grayscale\n",
    "        ref_rgb_gray = cv.cvtColor(ref_rgb, cv.COLOR_BGR2GRAY)\n",
    "        rgb_gray = cv.cvtColor(rgb, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Compute SSIM between two images\n",
    "        (score, diff) = compare_ssim(ref_rgb_gray, rgb_gray, full=True)\n",
    "        diff = (diff * 255).astype(\"uint8\")\n",
    "        print(\"SSIM: {}\".format(score))\n",
    "\n",
    "        thresh = cv.threshold(diff, 0, 255, cv.THRESH_BINARY_INV | cv.THRESH_OTSU)[1]\n",
    "        contours, __ = cv.findContours(thresh.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        if len(contours) > 0: cv.drawContours(rgb, contours, -1, (0, 255, 0), 1)\n",
    "\n",
    "        if len(rgb)>0: cv.imshow('OPENCV - rgb', rgb)\n",
    "        if len(depth)>0: cv.imshow('OPENCV - diff', diff)\n",
    "        if len(depth)>0: cv.imshow('OPENCV - Threshold', thresh)\n",
    "\n",
    "        [ref_rgb, ref_depth] = S.getImageAndDepth()\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    S.step([], tau, ry.ControlMode.none)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 3\n",
    "Exercise 2 is doing foreground/background segmentation based on the RGB.\n",
    "\n",
    "Think about how one can do the same for depth.\n",
    "In particular, assume that ‘background’ has always the largest pixel depth – so when the depth of a pixel is less than before,\n",
    "then it must be foreground. Realize this within the simulation loop, where you have access to depth.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "points = []\n",
    "tau = .01\n",
    "\n",
    "for t in range(300):\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "        [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "        points = S.depthData2pointCloud(depth, fxfypxpy)\n",
    "        cameraFrame.setPointCloud(points, rgb)\n",
    "        V.recopyMeshes(C)\n",
    "        V.setConfiguration(C)\n",
    "\n",
    "        rgb_gray = cv.cvtColor(rgb, cv.COLOR_BGR2GRAY)\n",
    "        thresh = cv.threshold(rgb_gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)[1]\n",
    "\n",
    "        cv.normalize(depth, depth,  0, 255, cv.NORM_MINMAX)\n",
    "        #thresh_depth = cv.threshold(depth, .4, .2, cv.THRESH_BINARY)[1]\n",
    "\n",
    "\n",
    "        #kernel = np.ones((3,3),np.uint8)\n",
    "        #dilation = cv.dilate(depth, kernel, depth)\n",
    "\n",
    "        if len(rgb)>0: cv.imshow('OPENCV - rgb', rgb)\n",
    "        if len(depth)>0: cv.imshow('OPENCV - dilation', depth)\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    S.step([], tau, ry.ControlMode.none)\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "cv.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8b9e1f39",
   "language": "python",
   "display_name": "PyCharm (robotics-course)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}