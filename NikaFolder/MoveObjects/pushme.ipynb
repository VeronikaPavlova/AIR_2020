{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../build')\n",
    "import libry as ry\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "np.random.seed(25)\n",
    "\n",
    "RealWorld = ry.Config()\n",
    "\n",
    "RealWorld.addFile(\"../../scenarios/challenge.g\")\n",
    "#Change color of objects\n",
    "for o in range(0, 30):\n",
    "    # color = list(np.random.choice(np.arange(0, 1, 0.05), size=2)) + [1]\n",
    "    #color = list(np.random.choice(np.arange(0, 1, 0.01), size=3))\n",
    "    color = random.choice([[0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 0, 1], [1, 1, 0],\n",
    "                           [1, 0.5, 0], [0.5, 0, 1], [0, 1, 0.5], [0, 0.5, 1], [0.5, 1, 0]])\n",
    "    name = \"obj%i\" % o\n",
    "    RealWorld.frame(name).setColor(color)\n",
    "\n",
    "S = RealWorld.simulation(ry.SimulatorEngine.physx, True)\n",
    "S.addSensor(\"camera\")\n",
    "\n",
    "C = ry.Config()\n",
    "C.addFile('../../scenarios/pandasTable.g')\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(C)\n",
    "cameraFrame = C.frame(\"camera\")\n",
    "\n",
    "q0 = C.getJointState()\n",
    "R_gripper = C.frame(\"R_gripper\")\n",
    "R_gripper.setContact(1)\n",
    "L_gripper = C.frame(\"L_gripper\")\n",
    "L_gripper.setContact(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO:\n",
    "\n",
    "0. add a second camera?\n",
    "1. create a dict with ObjectID, Center of Object, Position and Orientation\n",
    "2. - Also save which other objects \"nearby\" (maybe save distance between the centroids).\n",
    "   - If the distance change the these are two different Objects and the connection can be deleted.\n",
    "   - Otherwise save that this is \"one object\" just different sides of the Object\n",
    "3. Track the objects all the time\n",
    "4. Test grasping an object depending on the position (write a function for grasping where the input is\n",
    "a position where the gripper has to go and his orientation. Or maybe just give an objects as input)\n",
    "\n",
    "TODO later:\n",
    "1. Sort the different Objects sizes\n",
    "   - If the height and width of the object is too big (could not be grasped) - then mark of save in a list\n",
    "   - Save which objects are one on another - maybe get the z Position and if z is heigher then th z of table it means one object is below\n",
    "        - maybe the push the object down\n",
    "   - (optional) if object is too far away, grasp another object and push the object nearer\n",
    "2.depending on size of the object maybe do something like that:\n",
    "   - push objects down, so that they are all on the table\n",
    "   - objects which can be grasped, put them on a free space, to grasp them later\n",
    "   - object which cannot be grasped push them towards the other hand and try to rotate them\n",
    "        - also put these objects somewhere where is a free space\n",
    "3 Stack objects one over another\n",
    "     - sort by size --> biggest objects first later the smaller ones\n",
    "     - calculate the rotation to put one edge on the table while the other side is still grasped. Then slide the gripper (halbkreis) out\n",
    "     - check if center is on the right spot\n",
    "     - maybe readjust with two hands the object if it is not on the right position.\n",
    "     - stack as many objects as possible --> Retake the experiment 5 times with same objects and 3*5 with different ones --> evaluate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#the focal length\n",
    "f = 0.895\n",
    "f = f * 360.\n",
    "#the relative pose of the camera\n",
    "# pcl.setRelativePose('d(-90 0 0 1) t(-.08 .205 .115) d(26 1 0 0) d(-1 0 1 0) d(6 0 0 1) ')\n",
    "fxfypxpy = [f, f, 320., 180.]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def detectObjects(rgb):\n",
    "\n",
    "    #canny edge detection\n",
    "    edges = cv.Canny(rgb, 20, 60)\n",
    "    edges = cv.dilate(edges, None, iterations=1)\n",
    "    edges = cv.erode(edges, None, iterations=1)\n",
    "\n",
    "    #find contours in edges\n",
    "    contours, hierarchy = cv.findContours(edges, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    good_contour = []   # good contours which are identified\n",
    "    hull_list = []      #conved hull - the end points of rectangle\n",
    "\n",
    "    for cnt in contours:\n",
    "        #if small contour area - ignore\n",
    "        if cv.contourArea(cnt) < 200:\n",
    "            continue\n",
    "\n",
    "        #Ignore the objects which are too far away or in the background\n",
    "        mask = np.zeros(rgb.shape[:2], np.uint8)\n",
    "        cv.drawContours(mask, cnt, -1, 255, 1)\n",
    "        mean_color = cv.mean(rgb, mask=mask)\n",
    "        mean_depth = cv.mean(depth, mask=mask)\n",
    "\n",
    "        #compute the approx shape - try to fit Poly in shape\n",
    "        approx = cv.approxPolyDP(cnt, 0.05 * cv.arcLength(cnt,True),True)\n",
    "\n",
    "\n",
    "        if mean_color[2] > 165 and mean_depth[0] < 2 and len(approx) < 5:\n",
    "\n",
    "            good_contour.append(cnt)\n",
    "            #get convex hull\n",
    "            hull = cv.convexHull(approx)\n",
    "            hull_list.append(hull)\n",
    "\n",
    "            # compute the center of the contour\n",
    "            M = cv.moments(approx)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                # draw the contour and center of the shape on the image\n",
    "                print(str(cX) + \" \" + str(cY))\n",
    "                cv.circle(rgb, (cX, cY), 7, (255, 255, 255), -1)\n",
    "                cv.putText(rgb, \"center\", (cX - 20, cY - 20),\n",
    "                           cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "                cv.drawContours(rgb, hull, -1, (255, 0, 255), 3)\n",
    "\n",
    "    return good_contour, edges\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 243\n",
      "305 94\n",
      "313 82\n",
      "140 232\n",
      "304 108\n",
      "305 93\n",
      "59 68\n",
      "123 113\n",
      "240 223\n",
      "217 210\n",
      "167 211\n",
      "118 233\n",
      "171 171\n",
      "88 136\n",
      "304 108\n",
      "305 93\n",
      "507 151\n",
      "629 316\n",
      "242 231\n",
      "185 215\n",
      "197 178\n",
      "468 189\n",
      "304 108\n",
      "305 93\n",
      "243 239\n",
      "141 244\n",
      "191 216\n",
      "210 180\n",
      "80 156\n",
      "62 162\n",
      "304 108\n",
      "305 93\n",
      "25 281\n",
      "243 239\n",
      "304 108\n",
      "305 93\n",
      "243 239\n",
      "193 215\n",
      "212 184\n",
      "304 108\n",
      "305 93\n",
      "241 234\n",
      "185 216\n",
      "203 185\n",
      "304 108\n",
      "305 93\n",
      "219 226\n",
      "173 217\n",
      "182 185\n",
      "304 108\n",
      "305 93\n",
      "169 204\n",
      "304 108\n",
      "305 93\n",
      "19 311\n",
      "132 251\n",
      "195 236\n",
      "140 209\n",
      "304 108\n",
      "305 93\n",
      "20 310\n",
      "90 246\n",
      "167 208\n",
      "205 212\n",
      "304 108\n",
      "305 93\n",
      "20 310\n",
      "186 246\n",
      "89 248\n",
      "125 229\n",
      "164 210\n",
      "204 212\n",
      "304 108\n",
      "305 93\n",
      "20 311\n",
      "186 246\n",
      "89 248\n",
      "125 229\n",
      "164 210\n",
      "204 212\n",
      "304 108\n",
      "305 93\n",
      "20 311\n",
      "186 246\n",
      "89 248\n",
      "125 229\n",
      "164 210\n",
      "204 212\n",
      "304 108\n",
      "305 93\n",
      "20 311\n",
      "186 246\n",
      "89 248\n",
      "125 229\n",
      "164 210\n",
      "204 212\n",
      "304 108\n",
      "305 93\n",
      "20 311\n",
      "186 246\n",
      "89 248\n",
      "125 229\n",
      "164 210\n",
      "204 212\n",
      "304 108\n",
      "305 93\n",
      "20 311\n",
      "186 246\n",
      "89 248\n",
      "125 229\n",
      "164 210\n",
      "204 212\n",
      "304 108\n",
      "305 93\n",
      "20 311\n",
      "186 246\n",
      "89 248\n",
      "125 229\n",
      "164 210\n",
      "204 212\n",
      "304 108\n",
      "305 93\n",
      "20 311\n",
      "186 246\n",
      "89 248\n",
      "125 229\n",
      "164 210\n",
      "204 212\n",
      "304 108\n",
      "305 93\n",
      "20 311\n",
      "186 246\n",
      "89 248\n",
      "125 229\n",
      "164 210\n",
      "204 212\n",
      "304 108\n",
      "305 93\n",
      "20 311\n",
      "186 246\n",
      "89 248\n",
      "125 229\n",
      "164 210\n",
      "204 212\n",
      "304 108\n",
      "305 93\n",
      "20 311\n",
      "186 246\n",
      "89 248\n",
      "125 229\n",
      "164 210\n",
      "204 212\n",
      "304 108\n",
      "305 93\n"
     ]
    }
   ],
   "source": [
    "points = []\n",
    "tau = .01\n",
    "t = 0\n",
    "\n",
    "while True:\n",
    "    time.sleep(0.01)\n",
    "    t += 1\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "        [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "        points = S.depthData2pointCloud(depth, fxfypxpy)\n",
    "        cameraFrame.setPointCloud(points, rgb)\n",
    "        V.recopyMeshes(C)\n",
    "        V.setConfiguration(C)\n",
    "\n",
    "        good_contours, edges = detectObjects(rgb=rgb)\n",
    "\n",
    "        good = np.zeros(rgb.shape, np.uint8)\n",
    "        cv.drawContours(good, good_contours, -1, (0, 255, 0), 1)\n",
    "\n",
    "       # if len(rgb)>0: cv.imshow('OPENCV - rgb', rgb)\n",
    "        if len(edges)>0: cv.imshow('OPENCV - edges', edges)\n",
    "       # if len(good)>0: cv.imshow('OPENCV - depth', good)\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    S.step([], tau, ry.ControlMode.none)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8b9e1f39",
   "language": "python",
   "display_name": "PyCharm (robotics-course)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}